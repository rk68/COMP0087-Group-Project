{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    T5Tokenizer, \n",
    "    T5ForConditionalGeneration, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    AutoTokenizer, \n",
    "    AutoModelForSeq2SeqLM, \n",
    "    RobertaForMultipleChoice,\n",
    "    RobertaForQuestionAnswering,\n",
    "    RobertaTokenizer\n",
    ")\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "import torch\n",
    "import random\n",
    "import sympy as sp\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import model and datasets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model_name = 'google-t5/t5-small'\n",
    "\n",
    "aquarat = load_dataset('aqua_rat', split='train')\n",
    "aquarat_reduced = aquarat.shuffle(seed=42).select(range(1000))\n",
    "aquarat_test = load_dataset('aqua_rat', split='test')\n",
    "\n",
    "dataset2_name = 'ChilleD/SVAMP'\n",
    "svamp = load_dataset('ChilleD/SVAMP', split='train')\n",
    "svamp_reduced = svamp.shuffle(seed=42).select(range(400))\n",
    "\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained('google-t5/t5-small')\n",
    "tokenizer = t5_tokenizer\n",
    "\n",
    "t5_small = T5ForConditionalGeneration.from_pretrained('google-t5/t5-small')\n",
    "t5_small.save_pretrained('./t5_small')\n",
    "t5_base = T5ForConditionalGeneration.from_pretrained('google-t5/t5-base')\n",
    "t5_base.save_pretrained('./t5_base')\n",
    "\n",
    "flan_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "flan_t5 = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "flan_t5.save_pretrained('./flan_t5')\n",
    "\n",
    "roberta = RobertaForQuestionAnswering.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"FacebookAI/roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = \"../teacher_llm_dataset.db\"\n",
    "conn = sqlite3.connect(database_name)\n",
    "query = \"SELECT * FROM LLM_results\"\n",
    "df_custom = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "custom_dataset = Dataset.from_pandas(df_custom)\n",
    "custom_reduced = custom_dataset.shuffle(seed=42).select(range(400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'options', 'rationale', 'correct'],\n",
      "    num_rows: 1000\n",
      "})\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "Dataset({\n",
      "    features: ['ID', 'Question', 'Type', 'Answer', 'Body', 'Equation'],\n",
      "    num_rows: 700\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'options', 'rationale', 'correct'],\n",
      "    num_rows: 254\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>correct</th>\n",
       "      <th>LLMs_rationale</th>\n",
       "      <th>LLMs_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter invests a sum of money and gets back an ...</td>\n",
       "      <td>[\"A)653\", \"B)664\", \"C)698\", \"D)744\", \"E)700\"]</td>\n",
       "      <td>A</td>\n",
       "      <td>**Explanation:**\\n\\nGiven information:\\n\\n* Pe...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5670/(28*13.5) = ?</td>\n",
       "      <td>[\"A)11\", \"B)15\", \"C)16\", \"D)19\", \"E)18\"]</td>\n",
       "      <td>B</td>\n",
       "      <td>**Step 1: Calculate 28*13.5 = 369**\\n\\n**Step ...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If 11.25 m of a uniform steel rod weighs 42.75...</td>\n",
       "      <td>[\"A)22.8 kg\", \"B)26.6 kg\", \"C)28 kg\", \"D)26.5 ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Sure, here is the response:\\n\\nThe weight of a...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7, 26, 63, 124, 215, 342, (....)</td>\n",
       "      <td>[\"A)481\", \"B)511\", \"C)421\", \"D)391\", \"E)515\"]</td>\n",
       "      <td>B</td>\n",
       "      <td>**Explanation:**\\n\\nThe given sequence is form...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A and B can do a piece of work in 6 days. With...</td>\n",
       "      <td>[\"A)40 days\", \"B)16 days\", \"C)6 days\", \"D)5 da...</td>\n",
       "      <td>C</td>\n",
       "      <td>**Explanation:**\\n\\nSince A and B can complete...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Car X began traveling at an average speed of 3...</td>\n",
       "      <td>[\"A)105\", \"B)120\", \"C)140\", \"D)147\", \"E)98\"]</td>\n",
       "      <td>E</td>\n",
       "      <td>Sure, here is the completed request:\\n\\nCar X ...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Find the odd man out. 7, 14, 21, 28, 35, 50, 56</td>\n",
       "      <td>[\"A)50\", \"B)25\", \"C)51\", \"D)90\", \"E)115\"]</td>\n",
       "      <td>A</td>\n",
       "      <td>**Step 1:** Identify the pattern. The pattern ...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>The average height of 15 girls out of a class ...</td>\n",
       "      <td>[\"A)132 cms\", \"B)141 cms\", \"C)142 cms\", \"D)152...</td>\n",
       "      <td>B</td>\n",
       "      <td>**Explanation:**\\n\\nThe average height of 15 g...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>In a group of 100 people, 90 have an age of mo...</td>\n",
       "      <td>[\"A)0.1\", \"B)0.55\", \"C)0.65\", \"D)0.75\", \"E)0.85\"]</td>\n",
       "      <td>A</td>\n",
       "      <td>Sure, here's the explanation:\\n\\nThere are a t...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>How many 5 digit numbers can be formed which a...</td>\n",
       "      <td>[\"A)216\", \"B)3152\", \"C)240\", \"D)600\", \"E)305\"]</td>\n",
       "      <td>A</td>\n",
       "      <td>Sure, here is the completed request:\\n\\n### Qu...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Peter invests a sum of money and gets back an ...   \n",
       "1                                   5670/(28*13.5) = ?   \n",
       "2    If 11.25 m of a uniform steel rod weighs 42.75...   \n",
       "3                     7, 26, 63, 124, 215, 342, (....)   \n",
       "4    A and B can do a piece of work in 6 days. With...   \n",
       "..                                                 ...   \n",
       "995  Car X began traveling at an average speed of 3...   \n",
       "996    Find the odd man out. 7, 14, 21, 28, 35, 50, 56   \n",
       "997  The average height of 15 girls out of a class ...   \n",
       "998  In a group of 100 people, 90 have an age of mo...   \n",
       "999  How many 5 digit numbers can be formed which a...   \n",
       "\n",
       "                                               options correct  \\\n",
       "0        [\"A)653\", \"B)664\", \"C)698\", \"D)744\", \"E)700\"]       A   \n",
       "1             [\"A)11\", \"B)15\", \"C)16\", \"D)19\", \"E)18\"]       B   \n",
       "2    [\"A)22.8 kg\", \"B)26.6 kg\", \"C)28 kg\", \"D)26.5 ...       B   \n",
       "3        [\"A)481\", \"B)511\", \"C)421\", \"D)391\", \"E)515\"]       B   \n",
       "4    [\"A)40 days\", \"B)16 days\", \"C)6 days\", \"D)5 da...       C   \n",
       "..                                                 ...     ...   \n",
       "995       [\"A)105\", \"B)120\", \"C)140\", \"D)147\", \"E)98\"]       E   \n",
       "996          [\"A)50\", \"B)25\", \"C)51\", \"D)90\", \"E)115\"]       A   \n",
       "997  [\"A)132 cms\", \"B)141 cms\", \"C)142 cms\", \"D)152...       B   \n",
       "998  [\"A)0.1\", \"B)0.55\", \"C)0.65\", \"D)0.75\", \"E)0.85\"]       A   \n",
       "999     [\"A)216\", \"B)3152\", \"C)240\", \"D)600\", \"E)305\"]       A   \n",
       "\n",
       "                                        LLMs_rationale LLMs_answer  \n",
       "0    **Explanation:**\\n\\nGiven information:\\n\\n* Pe...           A  \n",
       "1    **Step 1: Calculate 28*13.5 = 369**\\n\\n**Step ...           B  \n",
       "2    Sure, here is the response:\\n\\nThe weight of a...           B  \n",
       "3    **Explanation:**\\n\\nThe given sequence is form...           B  \n",
       "4    **Explanation:**\\n\\nSince A and B can complete...           C  \n",
       "..                                                 ...         ...  \n",
       "995  Sure, here is the completed request:\\n\\nCar X ...           E  \n",
       "996  **Step 1:** Identify the pattern. The pattern ...           A  \n",
       "997  **Explanation:**\\n\\nThe average height of 15 g...           B  \n",
       "998  Sure, here's the explanation:\\n\\nThere are a t...           A  \n",
       "999  Sure, here is the completed request:\\n\\n### Qu...           A  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'options', 'correct', 'LLMs_rationale', 'LLMs_answer'],\n",
      "    num_rows: 400\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(aquarat_reduced)\n",
    "print(type(svamp_reduced))\n",
    "print(svamp)\n",
    "print(aquarat_test)\n",
    "display(df_custom)\n",
    "print(custom_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_aquarat(examples):\n",
    "    questions_and_options = [\n",
    "        f\"question: {q} options: {opts[0]} {opts[1]} {opts[2]} {opts[3]} {opts[4]}.\" \n",
    "        for q, opts in zip(examples[\"question\"], examples[\"options\"])]\n",
    "\n",
    "    correct_answers = [opts[ord(examples[\"correct\"][i]) - ord('A')] for i, opts in enumerate(examples[\"options\"])]\n",
    "\n",
    "    input_encodings = tokenizer(questions_and_options, padding=\"max_length\", truncation=True, max_length=512)\n",
    "    target_encodings = tokenizer(correct_answers, padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_encodings.input_ids,\n",
    "        \"attention_mask\": input_encodings.attention_mask,\n",
    "        \"labels\": target_encodings.input_ids,\n",
    "        \"inputs\": questions_and_options,\n",
    "        \"answers\": correct_answers\n",
    "    }\n",
    "\n",
    "def preprocess_svamp(examples):\n",
    "    questions_and_options = [\n",
    "        f\"question: {q} context: {bod}\" \n",
    "        for q, bod in zip(examples[\"Question\"], examples[\"Body\"])]\n",
    "\n",
    "    correct_answers = [str(ans) for ans in examples[\"Answer\"]]\n",
    "\n",
    "    input_encodings = tokenizer(questions_and_options, padding=\"max_length\", truncation=True, max_length=512)\n",
    "    target_encodings = tokenizer(correct_answers, padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_encodings.input_ids,\n",
    "        \"attention_mask\": input_encodings.attention_mask,\n",
    "        \"labels\": target_encodings.input_ids\n",
    "    }\n",
    "    \n",
    "def preprocess_custom(examples):\n",
    "    options = [re.findall(r'\"([^\"]+)\"', text) for text in examples[\"options\"]]\n",
    "\n",
    "    questions_and_options = [\n",
    "        f\"question: {q} options: {opts[0]} {opts[1]} {opts[2]} {opts[3]} {opts[4]}\" \n",
    "        for q, opts in zip(examples[\"question\"], options)]\n",
    "\n",
    "    correct_answers = [corr for corr in examples[\"correct\"]]\n",
    "\n",
    "    input_encodings = tokenizer(questions_and_options, padding=\"max_length\", truncation=True, max_length=512)\n",
    "    target_encodings = tokenizer(correct_answers, padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_encodings.input_ids,\n",
    "        \"attention_mask\": input_encodings.attention_mask,\n",
    "        \"labels\": target_encodings.input_ids,\n",
    "        \"inputs\": questions_and_options,\n",
    "        \"answers\": correct_answers\n",
    "    }\n",
    "\n",
    "def ask_math_question(input_ids, model, tokenizer):\n",
    "    # Generate the output ids with the model\n",
    "    output_ids = model.generate(input_ids, max_length=50, num_beams=5, early_stopping=True)[0]\n",
    "    # Decode the generated ids to get the answer\n",
    "    answer = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065e0654afab431b98f932ea51d9e50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "A\n",
      "Dataset({\n",
      "    features: ['question', 'options', 'rationale', 'correct', 'input_ids', 'attention_mask', 'labels', 'inputs', 'answers'],\n",
      "    num_rows: 1000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'options', 'rationale', 'correct', 'input_ids', 'attention_mask', 'labels', 'inputs', 'answers', 'ID', 'Question', 'Type', 'Answer', 'Body', 'Equation'],\n",
      "    num_rows: 1700\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'options', 'correct', 'LLMs_rationale', 'LLMs_answer', 'input_ids', 'attention_mask', 'labels', 'inputs', 'answers'],\n",
      "    num_rows: 400\n",
      "})\n",
      "A)r / (r + b + w)\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing\n",
    "aqua_train_proc = aquarat_reduced.map(preprocess_aquarat, batched=True)\n",
    "svamp_train_proc = svamp.map(preprocess_svamp, batched=True)\n",
    "aqua_test_proc = aquarat_test.map(preprocess_aquarat, batched=True)\n",
    "custom_train_proc = custom_reduced.map(preprocess_custom, batched=True)\n",
    "print(type(custom_train_proc[0]['correct']))\n",
    "print(custom_train_proc[0]['correct'])\n",
    "\n",
    "#custom_train = df_custom.apply(lambda row: preprocess_custom(row), axis=1)\n",
    "\n",
    "dataset_mixed_train = concatenate_datasets([aqua_train_proc, svamp_train_proc])\n",
    "\n",
    "print(aqua_train_proc)\n",
    "print(dataset_mixed_train)\n",
    "print(custom_train_proc)\n",
    "print(aqua_train_proc['answers'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select model and dataset\n",
    "\n",
    "chosen_model = t5_small\n",
    "chosen_dataset = aqua_train_proc\n",
    "output_model = './t5-small_aquarat_fullfinetune'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select training parameters\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./full_checkpoints\",\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=5e-5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    #load_best_model_at_end=True,\n",
    "    #gradient_accumulation_steps=2,  # Accumulate gradients for 2 steps\n",
    "    #max_grad_norm=1.0,  # Clip gradients to have a maximum norm of 1.0\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=chosen_model,\n",
    "    args=training_args,\n",
    "    train_dataset=chosen_dataset,\n",
    "    # eval_dataset=processed_eval_dataset, # If you have an evaluation dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf64d5f49e564eb4a7e15328c53f76ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 15.2685, 'learning_rate': 5e-06, 'epoch': 0.4}\n",
      "{'loss': 9.984, 'learning_rate': 1e-05, 'epoch': 0.8}\n",
      "{'loss': 3.3519, 'learning_rate': 1.5e-05, 'epoch': 1.2}\n",
      "{'loss': 0.7892, 'learning_rate': 2e-05, 'epoch': 1.6}\n",
      "{'loss': 0.2485, 'learning_rate': 2.5e-05, 'epoch': 2.0}\n",
      "{'loss': 0.1655, 'learning_rate': 3e-05, 'epoch': 2.4}\n",
      "{'loss': 0.1064, 'learning_rate': 3.5e-05, 'epoch': 2.8}\n",
      "{'loss': 0.0452, 'learning_rate': 4e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0271, 'learning_rate': 4.5e-05, 'epoch': 3.6}\n",
      "{'loss': 0.0232, 'learning_rate': 5e-05, 'epoch': 4.0}\n",
      "{'loss': 0.0202, 'learning_rate': 4.5e-05, 'epoch': 4.4}\n",
      "{'loss': 0.0194, 'learning_rate': 4e-05, 'epoch': 4.8}\n",
      "{'loss': 0.0195, 'learning_rate': 3.5e-05, 'epoch': 5.2}\n",
      "{'loss': 0.0178, 'learning_rate': 3e-05, 'epoch': 5.6}\n",
      "{'loss': 0.0172, 'learning_rate': 2.5e-05, 'epoch': 6.0}\n",
      "{'loss': 0.0176, 'learning_rate': 2e-05, 'epoch': 6.4}\n",
      "{'loss': 0.0162, 'learning_rate': 1.5e-05, 'epoch': 6.8}\n",
      "{'loss': 0.0168, 'learning_rate': 1e-05, 'epoch': 7.2}\n",
      "{'loss': 0.0167, 'learning_rate': 5e-06, 'epoch': 7.6}\n",
      "{'loss': 0.0171, 'learning_rate': 0.0, 'epoch': 8.0}\n",
      "{'train_runtime': 604.9976, 'train_samples_per_second': 13.223, 'train_steps_per_second': 1.653, 'train_loss': 1.50939651709795, 'epoch': 8.0}\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "chosen_model.save_pretrained(output_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Testing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiandaws/miniconda3/envs/dsml_env/lib/python3.9/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "# Load models for comparison\n",
    "t5_small = T5ForConditionalGeneration.from_pretrained('./t5_small')\n",
    "t5_base = T5ForConditionalGeneration.from_pretrained('./t5_base')\n",
    "tuned_model = T5ForConditionalGeneration.from_pretrained('./custom_finetuning')\n",
    "aquarat_fulltuned = T5ForConditionalGeneration.from_pretrained('./t5-small_aquarat_fullfinetune')\n",
    "lora_tuned = T5ForConditionalGeneration.from_pretrained('../peft_tuned')\n",
    "\n",
    "trainging_data = chosen_dataset\n",
    "testing_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to prompt model\n",
    "\n",
    "def generate_answer(model, tokenizer, prompt):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    output_ids = model.generate(input_ids, max_length=50, num_beams=5, early_stopping=True)\n",
    "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return output\n",
    "\n",
    "def evaluate_model_accuracy(model, tokenizer, dataset):\n",
    "    model.eval()  # Put model in evaluation mode\n",
    "    correct = 0\n",
    "    total = len(dataset)\n",
    "\n",
    "    for i, (input, answer) in enumerate(zip(dataset['input_ids'], dataset['answer'])):\n",
    "\n",
    "        pred_answer = generate_answer(model, tokenizer, input)\n",
    "        #print(pred_answer)\n",
    "        #print(answer)\n",
    "        # Compare predicted answer to the actual answer\n",
    "        if pred_answer == answer:\n",
    "            correct += 1\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Testing... {i+1}/{total}')\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing T5-small on AquaRat\n",
      "Testing... 10/254\n",
      "Testing... 20/254\n",
      "Testing... 30/254\n",
      "Testing... 40/254\n",
      "Testing... 50/254\n",
      "Testing... 60/254\n",
      "Testing... 70/254\n",
      "Testing... 80/254\n",
      "Testing... 90/254\n",
      "Testing... 100/254\n",
      "Testing... 110/254\n",
      "Testing... 120/254\n",
      "Testing... 130/254\n",
      "Testing... 140/254\n",
      "Testing... 150/254\n",
      "Testing... 160/254\n",
      "Testing... 170/254\n",
      "Testing... 180/254\n",
      "Testing... 190/254\n",
      "Testing... 200/254\n",
      "Testing... 210/254\n",
      "Testing... 220/254\n",
      "Testing... 230/254\n",
      "Testing... 240/254\n",
      "Testing... 250/254\n",
      "T5_small AquaRat accuracy: 0.003937007874015748\n"
     ]
    }
   ],
   "source": [
    "print('Testing T5-small on AquaRat')\n",
    "t5_aquarat_accuracy = evaluate_model_accuracy(t5_small, t5_tokenizer, aqua_test_proc)\n",
    "print(f'T5_small AquaRat accuracy: {t5_aquarat_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing T5-small_Aqurat_fulltuned on AquaRat\n",
      "Testing... 10/254\n",
      "Testing... 20/254\n",
      "Testing... 30/254\n",
      "Testing... 40/254\n",
      "Testing... 50/254\n",
      "Testing... 60/254\n",
      "Testing... 70/254\n",
      "Testing... 80/254\n",
      "Testing... 90/254\n",
      "Testing... 100/254\n",
      "Testing... 110/254\n",
      "Testing... 120/254\n",
      "Testing... 130/254\n",
      "Testing... 140/254\n",
      "Testing... 150/254\n",
      "Testing... 160/254\n",
      "Testing... 170/254\n",
      "Testing... 180/254\n",
      "Testing... 190/254\n",
      "Testing... 200/254\n",
      "Testing... 210/254\n",
      "Testing... 220/254\n",
      "Testing... 230/254\n",
      "Testing... 240/254\n",
      "Testing... 250/254\n",
      "T5-small_Aqurat_fulltuned AquaRat accuracy: 0.16535433070866143\n"
     ]
    }
   ],
   "source": [
    "print('Testing T5-small_Aqurat_fulltuned on AquaRat')\n",
    "t5_aquaratfulltuned_aquarat_accuracy = evaluate_model_accuracy(aquarat_fulltuned, t5_tokenizer, aqua_test_proc)\n",
    "print(f'T5-small_Aqurat_fulltuned AquaRat accuracy: {t5_aquaratfulltuned_aquarat_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing T5-small_Aqurat_lora on AquaRat\n",
      "Testing... 10/254\n",
      "Testing... 20/254\n",
      "Testing... 30/254\n",
      "Testing... 40/254\n",
      "Testing... 50/254\n",
      "Testing... 60/254\n",
      "Testing... 70/254\n",
      "Testing... 80/254\n",
      "Testing... 90/254\n",
      "Testing... 100/254\n",
      "Testing... 110/254\n",
      "Testing... 120/254\n",
      "Testing... 130/254\n",
      "Testing... 140/254\n",
      "Testing... 150/254\n",
      "Testing... 160/254\n",
      "Testing... 170/254\n",
      "Testing... 180/254\n",
      "Testing... 190/254\n",
      "Testing... 200/254\n",
      "Testing... 210/254\n",
      "Testing... 220/254\n",
      "Testing... 230/254\n",
      "Testing... 240/254\n",
      "Testing... 250/254\n",
      "T5-small_Aqurat_lora AquaRat accuracy: 0.2440944881889764\n"
     ]
    }
   ],
   "source": [
    "print('Testing T5-small_Aqurat_lora on AquaRat')\n",
    "t5_aquaratlora_aquarat_accuracy = evaluate_model_accuracy(lora_tuned, t5_tokenizer, aqua_test_proc)\n",
    "print(f'T5-small_Aqurat_lora AquaRat accuracy: {t5_aquaratlora_aquarat_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing flan_T5 on AquaRat\n",
      "Testing... 10/254\n",
      "Testing... 20/254\n",
      "Testing... 30/254\n",
      "Testing... 40/254\n",
      "Testing... 50/254\n",
      "Testing... 60/254\n",
      "Testing... 70/254\n",
      "Testing... 80/254\n",
      "Testing... 90/254\n",
      "Testing... 100/254\n",
      "Testing... 110/254\n",
      "Testing... 120/254\n",
      "Testing... 130/254\n",
      "Testing... 140/254\n",
      "Testing... 150/254\n",
      "Testing... 160/254\n",
      "Testing... 170/254\n",
      "Testing... 180/254\n",
      "Testing... 190/254\n",
      "Testing... 200/254\n",
      "Testing... 210/254\n",
      "Testing... 220/254\n",
      "Testing... 230/254\n",
      "Testing... 240/254\n",
      "Testing... 250/254\n",
      "flan_T5 AquaRat accuracy: 0.22440944881889763\n"
     ]
    }
   ],
   "source": [
    "print('Testing flan_T5 on AquaRat')\n",
    "flanT5_aquarat_accuracy = evaluate_model_accuracy(flan_t5, t5_tokenizer, aqua_test_proc)\n",
    "print(f'flan_T5 AquaRat accuracy: {flanT5_aquarat_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data\n",
    "\n",
    "prompt_list = []\n",
    "flan_t5_list = []\n",
    "t5_small_list = []\n",
    "t5_base_list = []\n",
    "correct_list = []\n",
    "t5_tuned = []\n",
    "\n",
    "shuffled_dataset = custom_train_proc.shuffle(seed=42)\n",
    "\n",
    "for qid in range(20):\n",
    "    prompt = tokenizer.decode(shuffled_dataset['input_ids'][qid], skip_special_tokens=True)\n",
    "    answer = tokenizer.decode(shuffled_dataset['labels'][qid], skip_special_tokens=True)\n",
    "    promptflan = flan_tokenizer.decode(shuffled_dataset['input_ids'][qid], skip_special_tokens=True)\n",
    "\n",
    "    prompt_list.append(prompt)\n",
    "    flan_t5_list.append(generate_answer(flan_t5, flan_tokenizer, promptflan))\n",
    "    t5_small_list.append(generate_answer(t5_small, tokenizer, prompt))\n",
    "    t5_base_list.append(generate_answer(t5_base, tokenizer, prompt))\n",
    "    t5_tuned.append(generate_answer(aquarat_fulltuned, tokenizer, prompt))\n",
    "    correct_list.append(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: If the average (arithmetic mean) of x + 2, x + 3, and x + 4 is 0, then x = options: A)u20134 B)u20133 C)u20132 D)u20131 E)0\n",
      "Correct Answer: B\n",
      "Flan-T5: C\n",
      "T5_small before Fine-tuning: x = options\n",
      "T5_base before Fine-tuning: x = options\n",
      "T5 after Fine-tuning: C)u20132\n",
      "\n",
      "question: How many seconds will it take for a car that is traveling at a constant rate of 90 miles per hour to travel a distance of 22 yards? (1 mile = 1,160 yards) options: A)0.8 B)0.5 C)1.0 D)1.1 E)1.2\n",
      "Correct Answer: B\n",
      "Flan-T5: C\n",
      "T5_small before Fine-tuning: 22 yards\n",
      "T5_base before Fine-tuning: 22 yards\n",
      "T5 after Fine-tuning: C)1.0\n",
      "\n",
      "question: Jack's toy box contains 13 toy soldiers, 7 model airplanes and 5 dolls. What is the probability that a randomly chosen toy from the box will be either a model airplane or a doll? options: A)35/252 B)12/25 C)(7/25)+(5/24) D)20/25 E)12\n",
      "Correct Answer: B\n",
      "Flan-T5: C\n",
      "T5_small before Fine-tuning: model airplanes and 5 dolls\n",
      "T5_base before Fine-tuning: model airplanes and 5 dolls\n",
      "T5 after Fine-tuning: D)20/25\n",
      "\n",
      "question: There are 12 students in a class. On the day the test was given, Ella was absent. The other 11 students took the test and their average was 74. The next day, Ella took the test, and with this grade included, the new average was 75. What was Ella's grade on the test? options: A)82 B)83 C)84 D)85 E)86\n",
      "Correct Answer: E\n",
      "Flan-T5: B\n",
      "T5_small before Fine-tuning: their average was 74\n",
      "T5_base before Fine-tuning: their average was 74\n",
      "T5 after Fine-tuning: C)84\n",
      "\n",
      "question: A question paper has 2parts, A & B, each containing 10 questions. If a student has to choose 8 from part A &5 from part B, in how many ways can he choose the questions? options: A)1100 B)1130 C)1135 D)1138 E)1140\n",
      "Correct Answer: E\n",
      "Flan-T5: C\n",
      "T5_small before Fine-tuning: 10 questions\n",
      "T5_base before Fine-tuning: 10 questions\n",
      "T5 after Fine-tuning: C)1135\n",
      "\n",
      "question: RAM and GOPAL invested in a business. They earned some profit which they divided in the ratio of 1:2. If RAM invested Rs.25, 000, the amount invested by GOPAL is: options: A)Rs. 65,000 B)Rs. 50,000 C)Rs. 80,000 D)Rs. 90,000 E)Rs. 60,000\n",
      "Correct Answer: B\n",
      "Flan-T5: C\n",
      "T5_small before Fine-tuning: Rs.25, 000\n",
      "T5_base before Fine-tuning: Rs.25, 000\n",
      "T5 after Fine-tuning: D)Rs. 90,000\n",
      "\n",
      "question: In an election, candidate A got 55% of the total valid votes. If 15% of the total votes were declared invalid and the total numbers of votes is 560000, find the number of valid vote polled in favor of candidate? options: A)261800 B)355800 C)356500 D)356800 E)357000\n",
      "Correct Answer: A\n",
      "Flan-T5: C\n",
      "T5_small before Fine-tuning: 55% of the total valid votes were declared invalid and the total numbers of votes is 560000\n",
      "T5_base before Fine-tuning: 55% of the total valid votes were declared invalid and the total numbers of votes is 560000\n",
      "T5 after Fine-tuning: A)261800\n",
      "\n",
      "question: A person buys an article at Rs.500. At what price should he sell the article so as to make a profit of 20%? options: A)600 B)299 C)797 D)179 E)642\n",
      "Correct Answer: A\n",
      "Flan-T5: C\n",
      "T5_small before Fine-tuning: at what price\n",
      "T5_base before Fine-tuning: at what price\n",
      "T5 after Fine-tuning: C)797\n",
      "\n",
      "question: In 2008, the profits of Company N were 10 percent of revenues. In 2009, the revenues of Company N fell by 20 percent, but profits were 10 percent of revenues. The profits in 2009 were what percent of the profits in 2008? options: A)105% B)80% C)120% D)124.2% E)138%\n",
      "Correct Answer: B\n",
      "Flan-T5: B\n",
      "T5_small before Fine-tuning: 20 percent\n",
      "T5_base before Fine-tuning: 20 percent\n",
      "T5 after Fine-tuning: C)120%\n",
      "\n",
      "question: A and B are working on an assignment. A takes 6 hours to type 32 pages on a computer, while B takes 5 hours to type 40 pages. How much time will they take, working together on two different computers to type an assignment of 110 pages? options: A)3 hours B)8 hours C)6 hours D)7 hours E)9 hours\n",
      "Correct Answer: B\n",
      "Flan-T5: C\n",
      "T5_small before Fine-tuning: A takes 6 hours to type 32 pages on a computer\n",
      "T5_base before Fine-tuning: A takes 6 hours to type 32 pages on a computer\n",
      "T5 after Fine-tuning: C)6 hours\n",
      "\n",
      "question: if 12401 is divided by any no. then quotient is 76 and remainder is 13.what is divisor? options: A)154 B)124 C)153 D)163 E)183\n",
      "Correct Answer: D\n",
      "Flan-T5: B\n",
      "T5_small before Fine-tuning: options: A)154 B)124 C)153 D)163 E)183\n",
      "T5_base before Fine-tuning: options: A)154 B)124 C)153 D)163 E)183\n",
      "T5 after Fine-tuning: D)163\n",
      "\n",
      "question: When a certain tree was first planted, it was 4 feet tall, and the height of the tree increased by a constant amount each year for the next 6 years. At the end of the 6th year, the tree was 1/3 taller than it was at the end of the 4th year. By how many feet did the height of the tree increase each year? options: A)3/10 B)2 C)1/2 D)2/3 E)6/5\n",
      "Correct Answer: B\n",
      "Flan-T5: C\n",
      "T5_small before Fine-tuning: 1/3\n",
      "T5_base before Fine-tuning: 1/3\n",
      "T5 after Fine-tuning: A)3/10\n",
      "\n",
      "question: A man buys an item at Rs. 750 and sells it at the loss of 10 percent. Then what is the selling price of that item options: A)Rs. 660 B)Rs. 675 C)Rs. 860 D)Rs. 960 E)None of these\n",
      "Correct Answer: B\n",
      "Flan-T5: B\n",
      "T5_small before Fine-tuning: loss of 10 percent\n",
      "T5_base before Fine-tuning: loss of 10 percent\n",
      "T5 after Fine-tuning: D)Rs. 960\n",
      "\n",
      "question: (1-1/n)+( 1-2/n)+(1-3/n)+...... up to n terms=? options: A)1/2n B)1/2(n-1) C)1/2n(n-1) D)none of these E)cannot be determined\n",
      "Correct Answer: B\n",
      "Flan-T5: D\n",
      "T5_small before Fine-tuning: options: A)1/2n B)1/2(n-1) C)1/2n(n-1) D)none of these E)cannot be determined\n",
      "T5_base before Fine-tuning: options: A)1/2n B)1/2(n-1) C)1/2n(n-1) D)none of these E)cannot be determined\n",
      "T5 after Fine-tuning: B)1/2(n-1)\n",
      "\n",
      "question: A certain sum amounts to Rs.7350 in 2 years and to Rs.8575 in 3 years.find the sum and rate percent options: A)5400 B)3400 C)5200 D)6500 E)5300\n",
      "Correct Answer: A\n",
      "Flan-T5: B\n",
      "T5_small before Fine-tuning: Rs.8575 in 3 years\n",
      "T5_base before Fine-tuning: Rs.8575 in 3 years\n",
      "T5 after Fine-tuning: C)5200\n",
      "\n",
      "question: Calculate the share of profit made by 2 business partners, who invested $1500 and $3500 respectively in a business if the profit made is $2500. options: A)$750,$1750 B)$710,$1400 C)$750,$1200 D)$753,$1400 E)$950,$1400\n",
      "Correct Answer: A\n",
      "Flan-T5: C\n",
      "T5_small before Fine-tuning: $950,$1400\n",
      "T5_base before Fine-tuning: $950,$1400\n",
      "T5 after Fine-tuning: C)$750,$1200\n",
      "\n",
      "question: In a class of 50 students the number of females is 2 more that 5 times the male number.How many males and females are there in the class options: A)42, 8 B)50,8 C)8,42 D)8,50 E)40,10\n",
      "Correct Answer: A\n",
      "Flan-T5: B\n",
      "T5_small before Fine-tuning: Females are 2 more that 5 times the male number\n",
      "T5_base before Fine-tuning: Females are 2 more that 5 times the male number\n",
      "T5 after Fine-tuning: B)50,8\n",
      "\n",
      "question: 405 sweets were distributed equally among children in such a way that the number of sweets received by each child is 20% of the total number of children. How many sweets did each child receive? options: A)7 B)9 C)18 D)45 E)None of these\n",
      "Correct Answer: B\n",
      "Flan-T5: C\n",
      "T5_small before Fine-tuning: none of these sweets were distributed equally among children\n",
      "T5_base before Fine-tuning: none of these sweets were distributed equally among children\n",
      "T5 after Fine-tuning: B)9\n",
      "\n",
      "question: A table is bought for Rs.600/- and sold at a loss of 12% find its selling price options: A)s.500/- B)s.530/- C)s.528/- D)s.600/- E)s.700/-\n",
      "Correct Answer: C\n",
      "Flan-T5: D\n",
      "T5_small before Fine-tuning: E)s.700/-\n",
      "T5_base before Fine-tuning: E)s.700/-\n",
      "T5 after Fine-tuning: E)s.700/-\n",
      "\n",
      "question: Life expectancy is defined by the formula 2SB/G, where S = shoe size, B = average monthly electric bill in dollars, and G = GMAT score. If Melvin's GMAT score is twice his monthly electric bill, and his life expectancy is 40, what is his shoe size? options: A)25 B)30 C)35 D)40 E)50\n",
      "Correct Answer: D\n",
      "Flan-T5: D\n",
      "T5_small before Fine-tuning: 40\n",
      "T5_base before Fine-tuning: 40\n",
      "T5 after Fine-tuning: C)35\n",
      "\n",
      "Correct: {'A': 5, 'B': 10, 'C': 1, 'D': 2, 'E': 2}\n",
      "t5 Fulltuned: {'A': 2, 'B': 3, 'C': 10, 'D': 4, 'E': 1}\n",
      "Flan  t5: {'A': 0, 'B': 6, 'C': 11, 'D': 3, 'E': 0}\n"
     ]
    }
   ],
   "source": [
    "correct_dict = {\n",
    "    'A':0,\n",
    "    'B':0,\n",
    "    'C':0,\n",
    "    'D':0,\n",
    "    'E':0\n",
    "}\n",
    "\n",
    "t5_fulltuned_dict = {\n",
    "    'A':0,\n",
    "    'B':0,\n",
    "    'C':0,\n",
    "    'D':0,\n",
    "    'E':0\n",
    "}\n",
    "\n",
    "flant5_dict = {\n",
    "    'A':0,\n",
    "    'B':0,\n",
    "    'C':0,\n",
    "    'D':0,\n",
    "    'E':0\n",
    "}\n",
    "\n",
    "for i in range(20):\n",
    "    print(prompt_list[i])\n",
    "    correct_dict[correct_list[i]] += 1\n",
    "    t5_fulltuned_dict[t5_tuned[i][0]] += 1\n",
    "    flant5_dict[flan_t5_list[i]] += 1\n",
    "    print(f'Correct Answer: {correct_list[i]}')\n",
    "    print(f'Flan-T5: {flan_t5_list[i]}')\n",
    "    print(f'T5_small before Fine-tuning: {t5_small_list[i]}')\n",
    "    print(f'T5_base before Fine-tuning: {t5_small_list[i]}')\n",
    "    print(f'T5 after Fine-tuning: {t5_tuned[i]}\\n')\n",
    "\n",
    "print(f'Correct: {correct_dict}')\n",
    "print(f't5 Fulltuned: {t5_fulltuned_dict}')\n",
    "print(f'Flan  t5: {flant5_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing data\n",
    "\n",
    "prompt_list_test = []\n",
    "flan_t5_list_test = []\n",
    "t5_list_test = []\n",
    "correct_list_test = []\n",
    "t5_tuned_test = []\n",
    "\n",
    "for qid in range(20):\n",
    "    prompt2 = tokenizer.decode(aqua_test_proc['input_ids'][qid], skip_special_tokens=True)\n",
    "    answer2 = tokenizer.decode(aqua_test_proc['labels'][qid], skip_special_tokens=True)\n",
    "    promptflan = flan_tokenizer.decode(aqua_test_proc['input_ids'][qid], skip_special_tokens=True)\n",
    "    #promptroberta = roberta_tokenizer.decode(processed_dataset['input_ids'][qid], skip_special_tokens=True)\n",
    "\n",
    "    prompt_list_test.append(prompt2)\n",
    "    flan_t5_list_test.append(generate_answer(flan_t5, flan_tokenizer, promptflan))\n",
    "    t5_list_test.append(generate_answer(t5_small, tokenizer, prompt2))\n",
    "    t5_tuned_test.append(generate_answer(aquarat_fulltuned, tokenizer, prompt2))\n",
    "    correct_list_test.append(answer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: A car is being driven, in a straight line and at a uniform speed, towards the base of a vertical tower. The top of the tower is observed from the car and, in the process, it takes 10 minutes for the angle of elevation to change from 45° to 60°. After how much more time will this car reach the base of the tower? options: A)5(3 + 1) B)6(3 + 2) C)7(3 – 1) D)8(3 – 2) E)None of these.\n",
      "Correct Answer: A)5(3 + 1)\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: a uniform speed\n",
      "T5 after Fine-tuning: C)7(3 – 1)\n",
      "Correct: False\n",
      "\n",
      "question: The original price of an item is discounted 22%. A customer buys the item at this discounted price using a $20-off coupon. There is no tax on the item, and this was the only item the customer bought. If the customer paid $1.90 more than half the original price of the item, what was the original price of the item? options: A)$61 B)$65 C)$67.40 D)$70 E)$78.20.\n",
      "Correct Answer: E)$78.20\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: 78.20\n",
      "T5 after Fine-tuning: C)$67.40\n",
      "Correct: False\n",
      "\n",
      "question: Find out which of the following values is the multiple of X, if it is divisible by 9 and 12? options: A)36 B)15 C)17 D)5 E)7.\n",
      "Correct Answer: A)36\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: options: A)36 B)15 C)17 D)5 E)7\n",
      "T5 after Fine-tuning: C)17\n",
      "Correct: False\n",
      "\n",
      "question: If the probability that Stock A will increase in value during the next month is 0.56, and the probability that Stock B will increase in value during the next month is 0.74. What is the greatest value for the probability that neither of these two events will occur? options: A)0.22 B)0.26 C)0.37 D)0.46 E)0.63.\n",
      "Correct Answer: B)0.26\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: the probability that Stock B will increase in value during the next month is 0.74\n",
      "T5 after Fine-tuning: C)0.37\n",
      "Correct: False\n",
      "\n",
      "question: A trader sold an article at a profit of 20% for Rs.360. What is the cost price of the article? options: A)270 B)300 C)280 D)320 E)315.\n",
      "Correct Answer: B)300\n",
      "Flan-T5: D\n",
      "T5 before Fine-tuning: Rs.360\n",
      "T5 after Fine-tuning: C)280\n",
      "Correct: False\n",
      "\n",
      "question: 20 marbles were pulled out of a bag of only white marbles, painted black, and then put back in. Then, another 20 marbles were pulled out, of which 1 was black, after which they were all returned to the bag. If the percentage of black marbles pulled out the second time represents their percentage in the bag, how many marbles in total Q does the bag currently hold? options: A)40 B)200 C)380 D)400 E)3200.\n",
      "Correct Answer: D)400\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: 1 was black\n",
      "T5 after Fine-tuning: A)40\n",
      "Correct: False\n",
      "\n",
      "question: Find the total no. of distinct bike no.'s that can beformed using 2 letters followed by 2 no.'s. How many letters need to be distinct? options: A)74453 B)64543 C)74325 D)65000 E)97656.\n",
      "Correct Answer: D)65000\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: bike no.'s\n",
      "T5 after Fine-tuning: C)74325\n",
      "Correct: False\n",
      "\n",
      "question: A train running at a speed of 100 miles/hour, takes 10 hours to reach its destination. After covering quarter of the distance, it starts raining and the train has to be slowed to speed of 75 miles/hour. What is the total journey duration? options: A)10 B)11.5 C)12.5 D)13.5 E)15.\n",
      "Correct Answer: C)12.5\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: 75 miles/hour\n",
      "T5 after Fine-tuning: B)11.5\n",
      "Correct: False\n",
      "\n",
      "question: Of the 200 students in a school, at least 45% attended the prom night and at least 35% took part in the debating session. What is the maximum number of students who could have neither attended the prom night nor the debating session? options: A)27 B)81 C)90 D)99 E)110.\n",
      "Correct Answer: E)110\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: maximum number of students who could have neither attended the prom night nor the debating session?\n",
      "T5 after Fine-tuning: C)90\n",
      "Correct: False\n",
      "\n",
      "question: A sales person gets a 10% commission on each sale he makes. How many sales of $250 each must he make in order to reach a salary of at least $1000? options: A)15 B)24 C)25 D)40 E)52.\n",
      "Correct Answer: D)40\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: a 10% commission\n",
      "T5 after Fine-tuning: C)25\n",
      "Correct: False\n",
      "\n",
      "question: A company produces 420 units of a particular computer component every month, at a production cost to the company of $110 per component, and sells all of the components by the end of each month. What is the minimum selling price per component that will guarantee that the yearly profit (revenue from sales minus production costs) will be at least $626,400? options: A)226 B)230 C)240 D)260 E)280.\n",
      "Correct Answer: B)230\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: options: A)226 B)230 C)240 D)260 E)280\n",
      "T5 after Fine-tuning: B)230\n",
      "Correct: True\n",
      "\n",
      "question: At a certain factory, 10 percent of the staplers produced on Monday were defective and 2 percent of the non-defective staplers were rejected by mistake. If 72 of the non-defective staplers were rejected, what was the number of staplers produced that day? options: A)4,000 B)4,200 C)4,500 D)4,800 E)5,000.\n",
      "Correct Answer: A)4,000\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: 72\n",
      "T5 after Fine-tuning: C)4,500\n",
      "Correct: False\n",
      "\n",
      "question: Machine A puts out a yo-yo every 6 minutes. Machine B puts out a yo-yo every 9 minutes. After how many minutes will they have produced 10 yo-yos? options: A)24 minutes B)32 minutes C)36 minutes D)64 minutes E)72 minutes.\n",
      "Correct Answer: C)36 minutes\n",
      "Flan-T5: B\n",
      "T5 before Fine-tuning: 9 minutes\n",
      "T5 after Fine-tuning: A)24 minutes\n",
      "Correct: False\n",
      "\n",
      "question: Add: +45 and -30 options: A)-30 B)+30 C)0 D)15 E)-15.\n",
      "Correct Answer: D)15\n",
      "Flan-T5: B\n",
      "T5 before Fine-tuning: +45\n",
      "T5 after Fine-tuning: D)15\n",
      "Correct: True\n",
      "\n",
      "question: In how many ways can the letters of the word \"PROBLEC\" be rearranged to make 7 letter words such that none of the letters repeat? options: A)2! B)3! C)7! D)8! E)9!.\n",
      "Correct Answer: C)7!\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: 7\n",
      "T5 after Fine-tuning: C)7!\n",
      "Correct: True\n",
      "\n",
      "question: Let A and B be independent events with P (A) = 0.2 and P(B) = 0.8. Find P(A/B)? options: A)0.2 B)0.4 C)0.6 D)1.2 E)1.5.\n",
      "Correct Answer: A)0.2\n",
      "Flan-T5: B\n",
      "T5 before Fine-tuning: P(A/B) = 0.8\n",
      "T5 after Fine-tuning: C)0.6\n",
      "Correct: False\n",
      "\n",
      "question: Consider there is an staircase elevator and you are coming down. If you walk 20 steps and stop, then you reach bottom in 10 minutes. If you walk 10 steps and stop, you reach to the ground in 20 minutes. What is the speed of the elevator? options: A)1 step/minute B)2 step/minute C)3 step/minute D)4 step/minute E)None of the above.\n",
      "Correct Answer: A)1 step/minute\n",
      "Flan-T5: B\n",
      "T5 before Fine-tuning: if you walk 20 steps and stop, then you reach bottom in 10 minutes.\n",
      "T5 after Fine-tuning: A)1 step/minute\n",
      "Correct: True\n",
      "\n",
      "question: Last year, a Home Appliance Store sold an average(arithmetic mean) of 42 microwave ovens per month. In the first 10 months of this year,the store has sold an average(arithmetic mean) of only 20 microwave ovens per month. What was the average number of microwave ovens sold per month during the entire 22 months period? options: A)21 B)30 C)31 D)32 E)None of the above.\n",
      "Correct Answer: D)32\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: 20 microwave ovens per month\n",
      "T5 after Fine-tuning: B)30\n",
      "Correct: False\n",
      "\n",
      "question: An exam is given in a certain class. The average (arithmetic mean) of the highest score and the lowest score is equal to x. If the average score for the entire class is equal to y and there are z students in the class, where z > 5, then in terms of x, y, and z, what is the average score for the class excluding the highest and lowest scorers? options: A)(zy – 2x)/z B)(zy – 2)/z C)(zx – y)/(z – 2) D)(zy – 2x)/(z -2) E)(zy – x)/(z + 2).\n",
      "Correct Answer: D)(zy – 2x)/(z -2)\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: x, y\n",
      "T5 after Fine-tuning: D)(zy – 2x)/(z -2)\n",
      "Correct: True\n",
      "\n",
      "question: [5 +?  19 - 15 - 7]/[13  13 - 156] = 6 options: A)4 B)4.5 C)5 D)5.5 E)6.5.\n",
      "Correct Answer: C)5\n",
      "Flan-T5: C\n",
      "T5 before Fine-tuning: 13 13 - 156] = 6 options: A)4 B)4.5 C)5 D)5.5 E)6.5\n",
      "T5 after Fine-tuning: C)5\n",
      "Correct: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(prompt_list_test[i])\n",
    "    print(f'Correct Answer: {correct_list_test[i]}')\n",
    "    print(f'Flan-T5: {flan_t5_list_test[i]}')\n",
    "    print(f'T5 before Fine-tuning: {t5_list_test[i]}')\n",
    "    print(f'T5 after Fine-tuning: {t5_tuned_test[i]}')\n",
    "    print(f'Correct: {correct_list_test[i] == t5_tuned_test[i]}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative results can be good for the result \n",
    "Probaly train on more samples than 200 to 400\n",
    "\n",
    "multiple choice answer from a model:\n",
    "BERT instead of seq2seq --> Score for every answer\n",
    "T5 (seq2seq) --> prompt to gen multiple outputs and select most freq answer\n",
    "Could ask model: How much from 0 to 100 do you believe this answer is correct?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add 2 cups of water to a bowl and mix well.\n"
     ]
    }
   ],
   "source": [
    "print(generate_answer(flan_t5, tokenizer, 'question: Add 3 and 2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
